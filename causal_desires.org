#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/style.css">
#+OPTIONS: num:nil toc:nil html-postamble:nil

#+TITLE: Causal Desires

#+HTML: <q> To model is human; causally, divine </q>

"Why?" We can't help but ask -- we need some kind of story that makes sense.  Knowing "why" suggests the ability to understand, predict and, if needed, change some pattern in the world.

The drive to rigorously understand these causal stories is one framing for the motivation of formal study. Here, causation itself is also formalized  -- an early taxonomy from Aristotle, today, undergraduates dutifully learning correlation is not causation. Pearl's causal calculus provides a statistical framework for drawing conclusions regarding the causality of modelled variables  [fn:1]. Pearl's causal calculus relies on the modeller providing a graph which specifies which variables can affect other variables (i.e. that confounder and mediator variables are known). This makes explicit the uncomfortable point that causality is a model property, subject to differences between that model and reality -- a point detailed in Norton's [[https://www.pitt.edu/~jdnorton/papers/003004.pdf]['Causation as Folk Science']]. 

The principle concern of causal calculus is decision making [fn:2]; questions like 'does smoking cause cancer' or 'does this intervention improve this health outcome'. This has two major distinctions from causal reasoning in our daily lives: its formality is really only merited where reliability has absolute priority (e.g. science), and decisions of daily life are often sequential, where the action we take affects the considered phenomena. In sequential decisions - whether to go to the gym, whether to get flowers for your partner - the action we take affects the state of the world or ourselves, in turn influencing our future decisions. 

Consider a rational agent choosing actions to achieve a certain outcome, based on an understanding that this action results in that outcome; a sort of counterfactual planning which is one theory of mind [fn:4]. This forward model impacts the agent's actions, but has a causality which may be incomplete. Such an incomplete causal story leaves room for plausible stories which invert the causality - where the effect is presented as a cause. The self-fullfilling prophecy is a sort of causality inversion: instead of a certain future causing the prophecy, the prophecy brings about that future by influencing actions of today.

Like any story, a causal story is a framing which centers certain facts and insights, and is typically incomplete. By being aware of our human need for a causal story, we can greet these stories of cause and effect with an appropriate amount of skepticism.  It may be that flipping the causality - considering the effect as a cause - provides useful insights.  

Some examples:

[fn:1] Pearl and Mackenzie, 'The Book of Why: The New Science of Cause and Effect', a number of shorter introductions [[https://www.inference.vc/untitled/][available]].
[fn:2] Although the causal graph can be extended to consider a time series, this is decidedly not the focus of the text. 
[fn:4] This theory of decision making is not the only one; see, e.g. [[https://arxiv.org/abs/1901.01291]['On the Utility of Model Learning in HRI']] by Choudhury, et al.

** Moore's law
Moore's law, the empirical rule of thumb that, in commercial semiconductor fabrication, the transistor count per chip doubles every two years. This observation, credited to Gordon Moore of Intel in 1965, was, at the time of its coinage, a model for predicting what computing power would be reasonable to expect in the future - helping software developers, consumers, and corporations plan their investments.

However, as many have noted, Moore's law does more than predict: it is also a benchmark, setting the industry tempo, driving R&D direction and funding.
 
** Love
The typical model is that love causes loving behavior. However, the feelings we assosciate with love could also be productively viewed as resulting from loving actions [fn:3].  This presents the alternative view that feelings of love emerge from and are reinforced by loving actions - that we inhabit our expressions. 

[fn:3] Nussbaum, "Love and the Individual: Romantic Rightness and Platonic Aspiration"

** Eternal salvation
A prototypical religious view is that righteous actions cause eternal salvation. The Puritans, especially Calvinists, typically espouse a form of predestination: that one does not choose salvation, 'the privilege of choice is God's alone'. Good behavior *results* from being elected for salvation, but does not *cause* it.

How does such a viewpoint affect the person who holds it? Someone contemplating an action which is, by their judgement, 'not good', and weighing this action with respect to the eternal salvation of their soul, it seems that predestination would lend a certain apathy, for their salvation is fixed. This seems to encourage a strong bifurcation in behavior: one who believes themselves destined for damnation has little reason to not act accordingly.

** Technology development
Let us assume, for the sake of argument, that a technology is a means to reaching certain ends - a technology makes it easier/possible to cause certain effects. Let's call this an affordance. What is the causal story of developing this technology? Looking at the practical means by which technology is created - investment of resources - someone decides to invest resources in the hopes of achieving a affordance. That is, the affordance drives (i.e. causes) the technology development. 

However, this is again an incomplete story. For example, existing technologies and methods are regularly pressed into new uses, which, due to their novelty, could not have driven development. Furthermore, much of develoment is driven by a specific use case, seeking to find a technology for a specific problem. So, does the planned affordance or use-case drive development? These complementary frameworks are sometimes called basic (or curiosity-driven) development vs. application-driven development. All development is a mixture of the two, but typically one is used to frame a process to funding agencies, investors, or other decision makers. For example, the DARPA research model is a 'right-to-left' method (presumably technologies move from left to right as they mature): look at what new use-cases fit their agency scope/objectives, then go 'shopping' in more basic research to find and foster supporting technologies.

This joint development of technology and use is part of what makes research and development difficult. This difficulty is exacerbated by the overwhelming tendency of developers and engineers to see the technology (which is ultimately a means) as the goal. For us developers, the goal *is* to develop. In many companies, these two frameworks are embodied in different roles, such as engineer and product manager. For the academic research community, use cases are often general and vague (e.g. make robots easier to program), implicitly or explicitly negotiated by the community, funding agencies, and commercial state-of-the-art.  
